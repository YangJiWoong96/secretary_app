# # JSON â†’ system ì£¼ì…ìš© ë¯¸ë‹ˆ í”„ë¡¬í”„íŠ¸
import json
import os
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple

from backend.config import get_settings
from backend.utils.logger import log_event

from .schema import Directives

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” "JSON ì§€ì‹œë¬¸ + ì§§ì€ ê³ ì • í—¤ë”"ë§Œ ë„£ìŠµë‹ˆë‹¤.
HEADER = (
    "ë„ˆëŠ” í•œêµ­ì–´ ì‚¬ìš©ì ì „ìš© ë¹„ì„œë‹¤. ì•„ë˜ JSON ì§€ì‹œë¬¸ì„ ëª¨ë“  ì£¼ì œì—ì„œ ì¼ê´€ë˜ê²Œ ì¤€ìˆ˜í•˜ë¼. "
    "ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ë³€ê²½ì„ ìš”êµ¬í•˜ë©´ 1íšŒ í™•ì¸ í›„ í•´ë‹¹ í„´ì— í•œí•´ ì„ì‹œë¡œ ì¡°ì •í•˜ë˜, ê¸°ë³¸ ì§€ì‹œë¬¸ì€ ìœ ì§€í•˜ë¼. "
    "ì•ˆì „/ì •ì±…(Guard) ê·œì¹™ì€ í•­ìƒ ëª¨ë“  ì„ í˜¸ë³´ë‹¤ ìš°ì„ í•œë‹¤. ì¶”ì¸¡ì´ë‚˜ í™˜ê°ì„ í•˜ì§€ ë§ê³ , ë¶ˆëª…í™•í•˜ë©´ ê°„ê²°íˆ ë˜ë¬¼ì–´ í™•ì¸í•˜ë¼."
)


def _compact_signals(sig: dict) -> dict:
    """
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ë§Œí¼ë§Œ ì¶•ì•½. í† í° ì‚¬ìš©ì„ ìµœì†Œí™”í•œë‹¤.
    - language: positive/negative/jondaemalë§Œ ìœ ì§€(ì†Œìˆ˜ì  1~2ìë¦¬)
    - topics: ìƒìœ„ 3ê°œ
    - style/meta/affect: í•µì‹¬ 1~2ê°œë§Œ
    - mobile: prime_time/avg_calendar_events_per_dayë§Œ
    """
    if not sig:
        return {}
    out = {}
    lang = sig.get("language") or {}
    if lang:
        out["language"] = {
            "positive": round(float(lang.get("positive_ratio", 0.0)), 2),
            "negative": round(float(lang.get("negative_ratio", 0.0)), 2),
            "jondaemal": round(float(lang.get("jondaemal_ratio", 0.0)), 2),
        }
    topics = sig.get("topics") or []
    if topics:
        out["topics"] = topics[:3]
    style = sig.get("style") or {}
    if style:
        out["style"] = {
            "prefers_short": style.get("prefers_short", 0.0),
            "emotional_intensity": style.get("emotional_intensity", 0.0),
        }
    meta = sig.get("meta") or {}
    if meta:
        out["meta"] = {"repeat_topic_ratio": meta.get("repeat_topic_ratio", 0.0)}
    affect = sig.get("affect") or {}
    if affect:
        out["affect"] = {
            "positive": affect.get("positive", 0.0),
            "negative": affect.get("negative", 0.0),
        }
    mobile = sig.get("mobile") or {}
    if mobile:
        out["mobile"] = {
            "prime_time": mobile.get("prime_time"),
            "avg_calendar_events_per_day": mobile.get("avg_calendar_events_per_day"),
        }
    return out


def compile_prompt_from_json(
    d: Directives, signals: dict | None = None, persona: dict | None = None
) -> str:
    # ê¼­ í•„ìš”í•œ í‚¤ë§Œ ìœ ì§€(í† í° ì ˆì•½)
    allow = [
        "tone",
        "formality",
        "emotion",
        "style",
        "verbosity",
        "emojis",
        "markdown",
        "language",
        "taboo_phrases",
        "do",
        "dont",
    ]
    slim = {
        k: v for k, v in (d or {}).items() if k in allow and v not in (None, [], "")
    }
    body = {"directives": slim}
    sig_comp = _compact_signals(signals or {})
    if sig_comp:
        body["signals"] = sig_comp
    if persona:
        # personaëŠ” í”„ë¡¬í”„íŠ¸ ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•´ bigfiveë§Œ ì¶•ì•½ ë°˜ì˜
        bf = (persona.get("bigfive") or {}) if isinstance(persona, dict) else {}
        if bf:
            body["persona"] = {"bigfive": bf}
    return HEADER + "\n\n" + json.dumps(body, ensure_ascii=False, separators=(",", ":"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ì…˜2: Directives-RAG í†µí•© ì»´íŒŒì¼ëŸ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class ProfilePriority:
    explicit: int = 10
    directives: int = 7
    inferred: int = 5
    default: int = 1


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš°ì„ ìˆœìœ„ Tie-break ê·œì¹™ ë° Directives â†” RAG í‚¤ ì •ê·œí™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ í‘œ
PRIO: dict[str, int] = {"explicit": 10, "directives": 7, "inferred": 5, "default": 1}

# ì •ì±…ì  ìš°ì„ ìˆœìœ„(ë™ë¥  ì‹œ) í‚¤ë³„ ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„ ê³ ì •
_POLICY_BY_KEY: dict[str, list[str]] = {
    # ì˜ˆ: ì¡´ëŒ“ë§/ë°˜ë§ ê´€ë ¨ ìš°ì„ ìˆœìœ„ëŠ” explicit > directives > inferred > default
    "communication_formality": ["explicit", "directives", "inferred", "default"],
}


def _better(a: dict, b: dict) -> dict:
    """
    ë™ë¥  í•´ì†Œ ë¡œì§:
    1) PRIO ë†’ì€ ì†ŒìŠ¤ ìš°ì„ 
    2) ts ìµœì‹ 
    3) confidence í° ê°’
    4) ì •ì±… ë§µ(ìˆìœ¼ë©´)ì—ì„œ ë” ì•ì„  ì†ŒìŠ¤
    """
    asrc = str(a.get("source") or "inferred")
    bsrc = str(b.get("source") or "inferred")
    if PRIO.get(asrc, 0) != PRIO.get(bsrc, 0):
        return a if PRIO.get(asrc, 0) > PRIO.get(bsrc, 0) else b
    ats = int(a.get("ts", 0) or 0)
    bts = int(b.get("ts", 0) or 0)
    if ats != bts:
        return a if ats > bts else b
    ac = float(a.get("confidence", 0) or 0)
    bc = float(b.get("confidence", 0) or 0)
    if ac != bc:
        return a if ac > bc else b
    key = str(a.get("norm_key") or b.get("norm_key") or "").strip()
    if key:
        order = {
            s: i
            for i, s in enumerate(
                _POLICY_BY_KEY.get(
                    key, ["explicit", "directives", "inferred", "default"]
                )
            )
        }
        if order.get(asrc, 99) != order.get(bsrc, 99):
            return a if order.get(asrc, 99) < order.get(bsrc, 99) else b
    # ì™„ì „ ë™ë¥ ì´ë©´ a ìœ ì§€
    return a


# Directives í‚¤ â†’ ì •ê·œí™” í‚¤ ë§¤í•‘ í…Œì´ë¸”
NORM_MAP: dict[str, str] = {
    "verbosity": "response_length",
    "formality": "communication_formality",
    "style": "communication_style",
}


def norm_key_from_directives(key: str) -> str:
    k = (key or "").strip()
    mapped = NORM_MAP.get(k, k)
    return mapped.lower().replace(".", "_")


def _merge_with_priority(
    rag_preferences: List[Dict[str, Any]],
    rag_traits: List[Dict[str, Any]],
    directives: Dict[str, Any],
    signals: Dict[str, Any],
) -> Dict[str, Any]:
    """
    ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‚¬ìš©ì í”„ë¡œí•„ ë³‘í•©

    - explicit > directives > inferred > default
    - ë™ì¼ norm_key ì¶©ëŒ ì‹œ ë†’ì€ ìš°ì„ ìˆœìœ„ ì±„íƒ
    """
    pr = ProfilePriority()
    items_map: Dict[str, Tuple[int, Dict[str, Any]]] = {}

    # 1) RAG preferences
    for pref in rag_preferences or []:
        nk = str(pref.get("norm_key") or "").strip()
        if not nk:
            continue
        source = str(pref.get("source") or "inferred").strip()
        prio = pr.explicit if source == "explicit" else pr.inferred
        if nk not in items_map:
            items_map[nk] = (prio, pref)
        else:
            cur_prio, cur_item = items_map[nk]
            if prio > cur_prio:
                items_map[nk] = (prio, pref)
            elif prio == cur_prio:
                items_map[nk] = (prio, _better(pref, cur_item))

    # 2) Directives (ì¤‘ê°„ ìš°ì„ ìˆœìœ„)
    for key, value in (directives or {}).items():
        nk = norm_key_from_directives(key)
        prio = pr.directives
        cand = {
            "key_path": key,
            "norm_key": nk,
            "value": value,
            "source": "directives",
            "confidence": 0.8,
        }
        if nk not in items_map:
            items_map[nk] = (prio, cand)
        else:
            cur_prio, cur_item = items_map[nk]
            if prio > cur_prio:
                items_map[nk] = (prio, cand)
            elif prio == cur_prio:
                items_map[nk] = (prio, _better(cand, cur_item))

    # ê²°ê³¼ ì •ë ¬
    sorted_items = sorted(items_map.values(), key=lambda x: -x[0])
    preferences = [item for _, item in sorted_items]
    traits = rag_traits or []
    return {"preferences": preferences, "traits": traits}


def _apply_token_budget(
    *,
    base_parts: list[str],
    overlay_sections: dict[str, str],
    budget_tokens: int = 300,
) -> tuple[list[str], dict[str, str]]:
    """
    í† í° ì˜ˆì‚° ê´€ë¦¬. ëŒ€ëµ ë¬¸ììˆ˜/4ë¥¼ í† í°ìœ¼ë¡œ ê°€ì •í•˜ì—¬ ì˜ˆì‚°ì„ ì´ˆê³¼í•˜ë©´ ìˆœì„œëŒ€ë¡œ ë“œë.
    1) hints ì œê±° â†’ 2) preferences(ë‚®ì€ confidence/ë¹„-explicit) ì¶•ì†Œ â†’ 3) topics ìƒìœ„ 2ê°œë§Œ
    """

    # ê°„ì´ í† í° ê³„ì‚°
    def _tok(s: str) -> int:
        return max(1, len(s) // 4)

    def _joined_len(parts: list[str], ov: dict[str, str]) -> int:
        total = "\n\n".join(parts + [v for v in ov.values() if v])
        return _tok(total)

    # 1) hints ìš°ì„  ì œê±°
    if _joined_len(base_parts, overlay_sections) > budget_tokens:
        overlay_sections["hints"] = ""

    # 2) preferences ì¤„ì´ê¸°: base_partsì—ì„œ [User Preferences] ì„¹ì…˜ì„ ì¤„ì—¬ ë³¸ë‹¤
    if _joined_len(base_parts, overlay_sections) > budget_tokens:
        new_base: list[str] = []
        for block in base_parts:
            if block.startswith("[User Preferences]"):
                lines = block.splitlines()
                header, rest = lines[0], lines[1:]
                # explicit ìš°ì„  ìœ ì§€, ë‚˜ë¨¸ì§€ ìµœëŒ€ 6ê°œë¡œ ì œí•œ
                explicit_lines = [ln for ln in rest if ln.startswith("â˜…-")]
                non_explicit = [ln for ln in rest if not ln.startswith("â˜…-")]
                trimmed = (
                    explicit_lines + non_explicit[: max(0, 6 - len(explicit_lines))]
                )
                new_block = "\n".join([header] + trimmed)
                new_base.append(new_block)
            else:
                new_base.append(block)
        base_parts = new_base

    # 3) topicsë¥¼ ìƒìœ„ 2ê°œë§Œ ìœ ì§€
    if _joined_len(
        base_parts, overlay_sections
    ) > budget_tokens and overlay_sections.get("style"):
        st_lines = overlay_sections["style"].splitlines()
        new_lines: list[str] = []
        for ln in st_lines:
            if ln.startswith("- Recent Topics:"):
                # í¬ë§·: "- Recent Topics: A(0.12), B(0.11), C(0.08)"
                try:
                    head, tail = ln.split(":", 1)
                    items = [x.strip() for x in tail.split(",") if x.strip()]
                    items = items[:2]
                    new_lines.append(f"- Recent Topics: {', '.join(items)}")
                except Exception:
                    new_lines.append(ln)
            else:
                new_lines.append(ln)
        overlay_sections["style"] = "\n".join(new_lines)

    return base_parts, overlay_sections


async def compile_unified_prompt_split(
    user_id: str,
    session_id: str,
    user_query: str,
    top_k: int = 5,
    has_evidence: bool | None = None,
) -> tuple[str, str, str]:
    """
    í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì»´íŒŒì¼ëŸ¬(ë¶„ë¦¬ ë²„ì „)
    - base: Header + BotGuard + Preferences + Persona (ë²„ì „ ìºì‹œ ëŒ€ìƒ)
    - overlay: Communication Style + Hints (ì¿¼ë¦¬ ë¯¼ê°, ì¿¼ë¦¬ í•´ì‹œ ìºì‹œ)
    Returns: (base_prompt, overlay_prompt, base_version)
    """
    from backend.directives.store import (
        load_directives,
        load_signals,
        version_of,
    )
    from backend.directives.store_user_ext import (
        load_persona_user,
        load_directives_user,
    )
    from backend.rag.profile_rag import get_profile_rag

    rag = get_profile_rag()

    # ì¡°ê±´ë¶€ ë¡œë“œ í”Œë˜ê·¸: í™˜ê²½ë³€ìˆ˜ì™€ í˜¸ì¶œì ì‹ í˜¸(has_evidence) ëª¨ë‘ ë§Œì¡±í•´ì•¼ í™œì„±í™”
    on_demand_enabled = (
        str(os.getenv("PROFILE_TIER_ON_DEMAND", "1")).lower() in ("1", "true", "yes")
        and has_evidence is not None
    )

    # 1) í”„ë¡œí•„ ê³„ì¸µ ì¡°íšŒ (Guard/Core/Dynamic) â€” í„´ ìºì‹œ ì ìš©
    try:
        from backend.directives.profile_cache_manager import get_profile_items_cached
        from backend.rag.profile_ids import bot_user_id_for

        # ì‚¬ìš©ì ìŠ¤ì½”í”„
        guard_items = await get_profile_items_cached(user_id, "guard")
        # Core: ì¦ê±° ì—†ì„ ë•Œë§Œ ë¡œë“œ (ì˜¨ë””ë§¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°)
        core_items = []
        if not on_demand_enabled or not has_evidence:
            core_items = await get_profile_items_cached(user_id, "core")
        # Dynamic: ì¦ê±° ìˆì„ ë•Œë§Œ ë¡œë“œ (ì˜¨ë””ë§¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°)
        dynamic_items_user = []
        if not on_demand_enabled or has_evidence:
            dynamic_items_user = await get_profile_items_cached(
                user_id, "dynamic", user_query, top_k=5
            )

        # ë´‡ ìŠ¤ì½”í”„(ì „ì—­)
        _bot_uid = bot_user_id_for(user_id)
        bot_guard_items = await get_profile_items_cached(_bot_uid, "guard")
        bot_dynamic_items = []
        if not on_demand_enabled or has_evidence:
            bot_dynamic_items = await get_profile_items_cached(
                _bot_uid, "dynamic", user_query, top_k=5
            )

        # Guard: ë´‡ ì „ì—­ ê°€ë“œë£° ìš°ì„  í¬í•¨
        guard_items = (bot_guard_items or []) + (guard_items or [])
        # Dynamic: ì‚¬ìš©ì/ë´‡ íŒíŠ¸ ë³‘í•©
        dynamic_items = (dynamic_items_user or []) + (bot_dynamic_items or [])
    except Exception:
        # í´ë°±: ê¸°ì¡´ 2ê³„ì¸µ ê²½ë¡œ ìœ ì§€
        user_prof = await rag.query_relevant_profile(
            user_id=user_id, user_input=user_query, top_k=top_k
        )
        bot_prof = await rag.query_bot_profile(user_id=user_id, user_input=user_query)
        guard_items = [
            {"key_path": k, "value": v, "source": "explicit", "tier": "guard"}
            for k, v in (bot_prof.get("guard") or {}).items()
        ]
        # Core/Dynamic ì¡°ê±´ë¶€ ë°˜ì˜
        core_items = []
        dynamic_items = []
        if not on_demand_enabled or not has_evidence:
            core_items = user_prof.get("preferences", [])
        if not on_demand_enabled or has_evidence:
            dynamic_items = bot_prof.get("hints", [])

    # 2) Directives/Signals/Persona ë¡œë“œ
    # ì‚¬ìš©ì ë²”ìœ„ ë£°ë¶ì„ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì„¸ì…˜ ë²”ìœ„ ë³€ê²½ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì„¸ì…˜ì—ì„œë§Œ ì–•ê²Œ ì˜¤ë²„ë ˆì´
    dirs_user, _meta_user = load_directives_user(user_id)
    dirs_sess, _meta_sess = load_directives(session_id)
    directives = {}
    try:
        directives = {**(dirs_user or {}), **(dirs_sess or {})}
    except Exception:
        directives = dirs_sess or dirs_user or {}
    signals = load_signals(session_id)
    # PersonaëŠ” ì‚¬ìš©ì ë²”ìœ„ë¡œ ê´€ë¦¬
    persona = load_persona_user(user_id) or {}

    # 3) ë³‘í•©: Core(ì¥ê¸° ì„ í˜¸) + Directives â†’ Preferences
    merged = _merge_with_priority(
        rag_preferences=core_items or [],
        rag_traits=[],
        directives=directives or {},
        signals=signals or {},
    )

    # 4) base/overlay êµ¬ì„± (ì„¸ì…˜3: Guard/Core/Dynamic)
    base_parts: list[str] = []
    base_parts.append(
        "You are an AI assistant for a Korean user. Follow these preferences consistently unless the user explicitly asks to change."
    )
    # BotProfile: ì •ì  í”„ë¡œí•„ì„ ìƒë‹¨ì— ê³ ì • ì£¼ì…
    try:
        from .bot_profile import load_static_bot_profile

        _bp = load_static_bot_profile()
        _bp_text = "[BotProfile]\n" + f"persona: {_bp.persona}\nstyle: {_bp.style}"
        base_parts.insert(1, _bp_text)
    except Exception:
        pass
    # Guard ìš°ì„  ì›ì¹™
    base_parts.append(
        "[Policy] Guard rules override user preferences. Never violate Guard."
    )

    # Tier 1: Guard (base, ë¶ˆë³€ ê·œì¹™)
    if guard_items:
        glines = ["[Tier 1: Guard - Immutable Rules]"]
        for it in guard_items:
            glines.append(f"â›” {it.get('key_path')}: {it.get('value')}")
        base_parts.append("\n".join(glines))

    # Tier 2: Core (base, ì¥ê¸° ì„ í˜¸)
    prefs = merged.get("preferences") or []
    if prefs:
        plines = ["[Tier 2: Core - Long-term Preferences]"]
        for it in prefs:
            tag = "â˜…" if (str(it.get("source")) == "explicit") else ""
            plines.append(f"{tag}- {it.get('key_path')}: {it.get('value')}")
        base_parts.append("\n".join(plines))

    # Persona (base)
    bf = (persona.get("bigfive") or {}) if isinstance(persona, dict) else {}
    if bf:
        base_parts.append(
            f"[Persona] Openness: {float(bf.get('openness',0.5)):.2f}, Conscientiousness: {float(bf.get('conscientiousness',0.5)):.2f}, Extraversion: {float(bf.get('extraversion',0.5)):.2f}"
        )

    # overlay: Communication Style + Tier 3 Dynamic (í˜„ì¬ ë§¥ë½)
    overlay_sections: dict[str, str] = {"style": "", "hints": ""}
    if signals:
        try:
            topics = signals.get("topics") or []
            top3 = ", ".join(
                f"{t.get('label')}({float(t.get('weight') or 0):.2f})"
                for t in topics[:3]
            )
        except Exception:
            top3 = ""
        style_line = signals.get("communication_style") or "mixed"
        emo_int = float(signals.get("emotional_intensity", 0.0) or 0.0)
        slines = ["[Communication Style]"]
        slines.append(f"- Style: {style_line}")
        if top3:
            slines.append(f"- Recent Topics: {top3}")
        slines.append(f"- Emotional Intensity: {emo_int:.2f}")
        overlay_sections["style"] = "\n".join(slines)

    if dynamic_items:
        hlines = ["[Tier 3: Dynamic - Current Context]"]
        for it in dynamic_items[:5]:
            val = it.get("value", "")
            hlines.append(f"ğŸ”„ {it.get('key_path')}: {val}")
        overlay_sections["hints"] = "\n".join(hlines)

    # (ì‹ ê·œ) í–‰ë™ ì‹ í˜¸ íŒíŠ¸: PreferenceScoreboard ìƒìœ„ í•­ëª© 2~3ê°œë§Œ í‘œì‹œ
    try:
        from backend.personalization.preference_scoreboard import (
            PreferenceScoreboard as _SB,
        )

        sb = _SB(get_settings().REDIS_URL)
        top_items_all = sb.top(user_id, top_n=8, include_pending=True)
        # behavior.* ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë§Œ í•„í„°ë§
        top_items = [
            (nk, e)
            for nk, e in (top_items_all or [])
            if str(nk).startswith("behavior.")
        ]
        if top_items:
            # Behavior Slots ì„¹ì…˜(ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ ë°˜ì˜)
            blines = ["[Behavior Slots]"]
            for nk, entry in top_items[:3]:
                sc = float((entry or {}).get("score", 0.0))
                st = str((entry or {}).get("status", ""))
                blines.append(f"- {nk} (status={st}, score={sc:.2f})")
            # overlayì— ë³‘í•©
            prev = overlay_sections.get("hints", "")
            overlay_sections["hints"] = (
                prev + ("\n" if prev else "") + "\n".join(blines)
            ).strip()
    except Exception:
        pass

    # 5) ë²„ì „ í•´ì‹œ(ë² ì´ìŠ¤ ì „ìš© ìš”ì†Œë¡œ êµ¬ì„±)
    version_obj = {
        "guard": guard_items,
        "core": prefs,
        "dynamic_keys": [it.get("key_path") for it in (dynamic_items or [])],
        "directives": directives,
        "persona": {"bigfive": bf} if bf else {},
    }
    base_version = version_of(version_obj)

    # 6) í† í° ì˜ˆì‚° ì ìš© + (ì„¸ì…˜6) ê³„ì¸µë³„ ì••ì¶• + 2ê³„ì¸µ ì••ì¶• ìºì‹œ/ë½
    # 6-1) 1ì°¨ ê°„ì´ ì˜ˆì‚° ì ìš©ìœ¼ë¡œ ê³¼ë„í•œ ì„¹ì…˜ ë“œë(íŒíŠ¸/í† í”½ ì¶•ì†Œ)
    base_parts, overlay_sections = _apply_token_budget(
        base_parts=base_parts, overlay_sections=overlay_sections, budget_tokens=300
    )

    # í”Œë˜ê·¸ë¡œ ì••ì¶• ê¸°ëŠ¥ ì˜¨/ì˜¤í”„ (ê¸°ë³¸ on)
    CTX_COMPRESS_ENABLED = bool(get_settings().CTX_COMPRESS_ENABLED)

    if CTX_COMPRESS_ENABLED:
        try:
            # ìºì‹œ ì¡°íšŒ ë° ë‹¨ì¼ë¹„í–‰ ë½
            from backend.context.compressor import compress_by_tier_async
            from backend.directives.store import (
                acquire_compress_lock,
                get_compressed_base,
                get_compressed_overlay,
                release_compress_lock,
                set_compressed_base,
                set_compressed_overlay,
            )
            from backend.utils.logger import log_event as _log

            settings_local = get_settings()
            model_name = settings_local.LLM_MODEL
            token_budget = 300

            # Guard/Core/Dynamic í…ìŠ¤íŠ¸ (êµ¬ì¡° ë³´ì¡´: key_path: value)
            guard_text = "\n".join(
                [
                    f"â›” {it.get('key_path')}: {it.get('value')}"
                    for it in (guard_items or [])
                ]
            )
            core_text = "\n".join(
                [f"{it.get('key_path')}: {it.get('value')}" for it in (prefs or [])]
            )
            dynamic_text = overlay_sections.get("hints", "")

            # 2ê³„ì¸µ ìºì‹œ í™•ì¸
            cached_base = get_compressed_base(
                user_id, base_version, model_name, token_budget
            )
            cached_overlay = get_compressed_overlay(
                session_id, user_query, model_name, token_budget
            )

            if cached_base and cached_overlay:
                try:
                    _log("compress_cache_hits", {"base": True, "overlay": True})
                except Exception:
                    pass
                # base_parts ì¬êµ¬ì„±
                base_parts = [
                    base_parts[0],
                    base_parts[1],
                    cached_base,
                ]
                overlay_sections["hints"] = cached_overlay
            else:
                # ë‹¨ì¼ë¹„í–‰ ë½
                lock_key, ok = acquire_compress_lock(
                    session_id, user_query, model_name, token_budget, ex_sec=5
                )
                if not ok and (cached_base or cached_overlay):
                    # ë¶€ë¶„ ìºì‹œë¼ë„ ìˆìœ¼ë©´ ì‚¬ìš©
                    try:
                        _log(
                            "compress_lock_denied_use_partial_cache",
                            {
                                "base_cached": bool(cached_base),
                                "overlay_cached": bool(cached_overlay),
                            },
                        )
                    except Exception:
                        pass
                    if cached_base:
                        base_parts = [base_parts[0], base_parts[1], cached_base]
                    if cached_overlay:
                        overlay_sections["hints"] = cached_overlay
                else:
                    try:
                        compressed = await compress_by_tier_async(
                            guard_text=guard_text,
                            core_text=core_text,
                            dynamic_text=dynamic_text,
                            total_budget=token_budget,
                        )

                        base_comp = []
                        if compressed.get("guard"):
                            base_comp.append(
                                "[Tier 1: Guard - Immutable Rules]\n"
                                + compressed["guard"]
                            )
                        if compressed.get("core"):
                            base_comp.append(
                                "[Tier 2: Core - Long-term Preferences]\n"
                                + compressed["core"]
                            )

                        base_joined = "\n\n".join(base_comp)
                        dyn_joined = (
                            "[Tier 3: Dynamic - Current Context]\n"
                            + compressed.get("dynamic", "")
                            if compressed.get("dynamic")
                            else ""
                        )

                        # ìºì‹œ ì €ì¥
                        set_compressed_base(
                            user_id, base_version, model_name, token_budget, base_joined
                        )
                        set_compressed_overlay(
                            session_id, user_query, model_name, token_budget, dyn_joined
                        )

                        # ë°˜ì˜
                        base_parts = [base_parts[0], base_parts[1]] + (
                            [base_joined] if base_joined else []
                        )
                        overlay_sections["hints"] = dyn_joined

                        try:
                            _log(
                                "compress_compiled",
                                {
                                    "base_tokens": max(1, len(base_joined) // 4),
                                    "dyn_tokens": max(0, len(dyn_joined) // 4),
                                    "budget": token_budget,
                                },
                            )
                        except Exception:
                            pass
                    finally:
                        if ok:
                            release_compress_lock(lock_key)
        except Exception:
            # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ê²½ë¡œ ìœ ì§€(ê°„ì´ í† í° ì˜ˆì‚°ë§Œ ì ìš©)
            pass

    base_prompt = "\n\n".join([p for p in base_parts if p])
    overlay_prompt = "\n\n".join(
        [v for v in (overlay_sections.get("style"), overlay_sections.get("hints")) if v]
    )

    # ë¡œê¹…
    try:
        log_event(
            "unified_prompt_compiled_split",
            {
                "session_id": session_id,
                "user_id": user_id,
                "version": base_version,
                "base_len": len(base_prompt or ""),
                "overlay_len": len(overlay_prompt or ""),
            },
        )
        # profile.loaded í…”ë ˆë©”íŠ¸ë¦¬ (ê³„ì¸µë³„ ë¡œë“œ ìˆ˜, ì¦ê±°/í”Œë˜ê·¸)
        log_event(
            "profile.loaded",
            {
                "guard_count": len(guard_items or []),
                "core_count": len((merged.get("preferences") or [])),
                "dynamic_count": len(dynamic_items or []),
                "has_evidence": has_evidence,
                "on_demand_enabled": on_demand_enabled,
            },
        )
    except Exception:
        pass

    return base_prompt, overlay_prompt, base_version


async def compile_unified_prompt(
    user_id: str,
    session_id: str,
    user_query: str,
    top_k: int = 5,
) -> tuple[str, str]:
    """
    í†µí•© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì»´íŒŒì¼ëŸ¬
    - RAG(Profile) + Directives + Signals + Persona â†’ System Prompt
    - explicit > directives > inferred ë³‘í•© ì •ì±… ì ìš©
    - ë²„ì „ í•´ì‹œë¥¼ í•¨ê»˜ ë°˜í™˜
    """
    base_prompt, overlay_prompt, base_version = await compile_unified_prompt_split(
        user_id=user_id, session_id=session_id, user_query=user_query, top_k=top_k
    )
    final_prompt = "\n\n".join([p for p in (base_prompt, overlay_prompt) if p])
    return final_prompt, base_version
