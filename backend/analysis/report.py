from __future__ import annotations

"""
ì¼/ì£¼ê°„ Markdown ë¦¬í¬íŠ¸ ìƒì„±ê¸°

ì—­í• :
- ê²€ìƒ‰ ìŠ¤ëƒ…ìƒ·(evidence/websnap)ì„ ê¸°ì¤€ìœ¼ë¡œ ì¼/ì£¼ê°„ ìƒìœ„ ì´ìŠˆ(ì œëª©)ì™€ ë¶„í¬ë¥¼ ìš”ì•½í•´ Markdownìœ¼ë¡œ ë°˜í™˜í•œë‹¤.
"""

from typing import Dict, List, Tuple
from pathlib import Path
from datetime import datetime, timedelta
import json
import re


def _snapshot_root() -> Path:
    return Path(__file__).resolve().parents[1] / "evidence" / "websnap"


def _normalize_title_text(title: str) -> str:
    t = str(title or "")
    t = re.sub(r"</?b>", "", t, flags=re.I)
    t = " ".join(t.split())
    return t


def _collect_counts_for_range(
    start_day: str, end_day: str, kinds: List[str]
) -> Dict[str, int]:
    """
    ë‚ ì§œ ë²”ìœ„(YYYYMMDD~YYYYMMDD) ë™ì•ˆ ì œëª©ë³„ ë“±ì¥ íšŸìˆ˜ í•©ì‚°.
    """
    counts: Dict[str, int] = {}
    root = _snapshot_root()
    try:
        sd = datetime.strptime(start_day, "%Y%m%d")
        ed = datetime.strptime(end_day, "%Y%m%d")
        cur = sd
        while cur <= ed:
            day_dir = root / cur.strftime("%Y%m%d")
            if day_dir.exists():
                for kind in kinds or []:
                    for fp in sorted(day_dir.glob(f"{kind}-*.jsonl")):
                        try:
                            with fp.open("r", encoding="utf-8") as f:
                                for line in f:
                                    try:
                                        rec = json.loads(line)
                                        title = _normalize_title_text(
                                            rec.get("title", "")
                                        )
                                        if not title:
                                            continue
                                        counts[title] = counts.get(title, 0) + 1
                                    except Exception:
                                        continue
                        except Exception:
                            continue
            cur += timedelta(days=1)
    except Exception:
        return counts
    return counts


def _format_markdown(
    title: str, period_desc: str, top_items: List[Tuple[str, int]]
) -> str:
    lines: List[str] = []
    lines.append(f"# {title}")
    lines.append("")
    lines.append(f"**ê¸°ê°„**: {period_desc}")
    lines.append(f"**ìƒì„±ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("## ğŸ”¥ TOP ì´ìŠˆ")
    lines.append("")
    if not top_items:
        lines.append("- (ìë£Œ ì—†ìŒ)")
    else:
        for i, (t, c) in enumerate(top_items, 1):
            lines.append(f"{i}. {t} â€” {c}íšŒ")
    lines.append("")
    lines.append("---")
    lines.append("*ë³¸ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
    return "\n".join(lines)


def generate_daily_report(kinds: List[str] | None = None, top_n: int = 10) -> str:
    kinds = kinds or ["news", "webkr", "blog"]
    today = datetime.now().strftime("%Y%m%d")
    counts = _collect_counts_for_range(today, today, kinds)
    top = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:top_n]
    md = _format_markdown("ğŸ“… ì¼ê°„ ì´ìŠˆ ìš”ì•½", today, top)
    return md


def generate_weekly_report(kinds: List[str] | None = None, top_n: int = 15) -> str:
    kinds = kinds or ["news", "webkr", "blog"]
    now = datetime.now()
    end_day = now.strftime("%Y%m%d")
    start_day = (now - timedelta(days=6)).strftime("%Y%m%d")
    counts = _collect_counts_for_range(start_day, end_day, kinds)
    top = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:top_n]
    md = _format_markdown("ğŸ—“ï¸ ì£¼ê°„ ì´ìŠˆ ìš”ì•½", f"{start_day} ~ {end_day}", top)
    return md


__all__ = ["generate_daily_report", "generate_weekly_report"]
